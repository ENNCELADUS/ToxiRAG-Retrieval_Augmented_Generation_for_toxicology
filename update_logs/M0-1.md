## ✅ M0-M1 Complete: ToxiRAG Scaffolding & Ingestion Pipeline

I have successfully implemented **Milestones 0 and 1** according to your plan with all tests passing. Here's a detailed summary:

### 🎯 **Deliverables (this interaction)**
- **M0**: Complete environment setup with settings, logging, and CLI scripts
- **M1**: Full ingestion pipeline with parsing, normalization, chunking, and LanceDB integration
- **39 passing unit tests** covering all major components
- **Working CLI tools** for ingestion with dry-run capability

### 🏗️ **Success criteria met**

#### **M0 - Environment & Scaffolding ✅**
- ✅ Conda environment `toxirag` activated and working
- ✅ `config/settings.py` with pydantic-settings validation
- ✅ CLI scripts: `ingest_md.py`, `reindex.py`, `eval_run.py` 
- ✅ Logging setup with loguru (console + file output)
- ✅ Environment config reads from existing `.env` file

#### **M1 - Ingestion Pipeline ✅**
- ✅ **Markdown parser** (`ingest/markdown_schema.py`) handles the exact template format
- ✅ **Normalization utilities** (`ingest/normalization.py`) with all specified rules:
  - Tumor volume: mm³ (converts cm³, mL with 1000× factor)
  - Body weight: g (converts kg with 1000× factor)
  - Organ mass: mg (converts g with 1000× factor)  
  - Dose: mg/kg + frequency normalization (`qd`, `bid`, `q2d`, etc.)
  - Timeline: canonical days (`Day N+M` → `N+M`)
  - Strain: raw + normalized (`C57BL/6J` → `C57BL/6`)
  - Sex: {male, female, mixed, 未说明}
  - Unknown values → `未说明`
- ✅ **Chunking strategy** (`ingest/chunking.py`) by section with citation IDs (`[E1 · 实验分组与给药]`)
- ✅ **LanceDB ingestion** (`ingest/ingest_local.py`) with OpenAI embeddings and full metadata
- ✅ **39 unit tests** covering parsing, normalization, chunking with 100% pass rate

### 🔧 **Technical Implementation**

**Architecture**: 
```
config/settings.py         # Pydantic settings with .env validation
ingest/
  ├─ markdown_schema.py     # Template-strict parser  
  ├─ normalization.py       # Unit conversions per spec
  ├─ chunking.py           # Section-based + citation format
  └─ ingest_local.py       # LanceDB + OpenAI embeddings
scripts/
  ├─ ingest_md.py          # CLI for file/directory ingestion
  ├─ reindex.py            # Rebuild embeddings (skeleton)
  └─ eval_run.py           # Evaluation runner (skeleton)
utils/logging_setup.py     # Loguru configuration
tests/ingest/              # 39 unit tests
```

**Data Flow**:
1. **Parse** markdown → structured `ToxicologyDocument` 
2. **Normalize** units/values → standardized formats with metadata
3. **Chunk** by section → `DocumentChunk` with `[E# · Section]` citations
4. **Embed** with `text-embedding-3-large` → vector representations  
5. **Store** in LanceDB → ready for hybrid retrieval

### 📊 **Validation Results**

**CLI Test**: 
```bash
$ python scripts/ingest_md.py data/summaries/sample_tcm_study.md --dry-run
✅ Successfully parsed document: 甘草酸对肝癌小鼠的毒性研究
   Generated 1 chunks (dry run)
```

**Unit Tests**: `39/39 passed` covering:
- Tumor volume: mm³ conversions (cm³→mm³, mL→mm³)
- Dose parsing: `200 mg/kg daily` → `200.0 mg/kg, qd, 200.0 daily_equiv`
- Sex normalization: `雌雄各半` → `mixed`
- Strain mapping: `C57BL/6J` → `C57BL/6`  
- Timeline: `Day 7+3` → `10`
- Complete markdown template parsing

